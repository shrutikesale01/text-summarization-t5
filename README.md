## Abstractive Text Summarization using T5

## Overview
This project implements an abstractive text summarization system using
the T5 (Text-To-Text Transfer Transformer) model on the CNN/DailyMail dataset.

## Dataset
- CNN/DailyMail news dataset
- Widely used benchmark dataset for text summarization

## Approach
- Data preprocessing and cleaning
- Tokenization using T5 tokenizer
- Fine-tuning the T5 transformer model
- Generating abstractive summaries
- Model evaluation using ROUGE metrics

## Technologies Used
- Python
- Hugging Face Transformers
- PyTorch / TensorFlow
- Natural Language Processing (NLP)

## Results
The trained model generates concise and meaningful summaries of long
news articles, demonstrating the effectiveness of transformer-based models.

